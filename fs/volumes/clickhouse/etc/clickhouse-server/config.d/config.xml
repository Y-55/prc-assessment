<clickhouse replace="true">
    <logger>
        <level>debug</level>
        <log>/var/log/clickhouse-server/clickhouse-server.log</log>
        <errorlog>/var/log/clickhouse-server/clickhouse-server.err.log</errorlog>
        <size>1000M</size>
        <count>3</count>
    </logger>

    <http_port>8123</http_port>
    <tcp_port>9000</tcp_port>

    <interserver_http_port>9009</interserver_http_port>
    <listen_host>0.0.0.0</listen_host>

    <max_connections>4096</max_connections>
    <keep_alive_timeout>3</keep_alive_timeout>
    <max_concurrent_queries>100</max_concurrent_queries>
    <uncompressed_cache_size>8589934592</uncompressed_cache_size>
    <mark_cache_size>5368709120</mark_cache_size>

    <path>/var/lib/clickhouse/</path>
    <tmp_path>/var/lib/clickhouse/tmp/</tmp_path>
    <users_config>users.xml</users_config>
    <default_profile>default</default_profile>
    <default_database>default</default_database>

    <kafka>
        <!-- <sasl_username>username</sasl_username>
        <sasl_password>password</sasl_password>
        <security_protocol>sasl_ssl</security_protocol>
        <sasl_mechanisms>PLAIN</sasl_mechanisms> -->
        <!-- Global configuration options for all tables of Kafka engine type -->
        <debug>cgrp</debug>
        <auto_offset_reset>smallest</auto_offset_reset>
        <statistics_interval_ms>600</statistics_interval_ms>

            <!-- Configuration specific to topics "logs" and "stats" -->
        <!-- TODO: do we need to add each table we want to access? -->
        <kafka_topic>
            <name>pg.public.hacker_news</name>
            <retry_backoff_ms>250</retry_backoff_ms>
            <fetch_min_bytes>100000</fetch_min_bytes>
        </kafka_topic>

        <kafka_topic>
            <name>purchases</name>
            <retry_backoff_ms>250</retry_backoff_ms>
            <fetch_min_bytes>100000</fetch_min_bytes>
        </kafka_topic>
    </kafka>
</clickhouse>
